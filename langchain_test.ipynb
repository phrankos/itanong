{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install  langchain==0.1.6 langchain-cli==0.0.21 langchain-openai==0.0.6 huggingface_hub==0.21.4 python-dotenv==1.0.0 pydantic==1.10.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: LLM Langchain RAG for SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain.llms import LlamaCpp, OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(repo_id=\"mrm8488/t5-base-finetuned-wikiSQL\",\n",
    "                          max_new_tokens=200)\n",
    "\n",
    "db_user = \"username\"\n",
    "db_password = \"password\"\n",
    "db_host = \"localhost\"\n",
    "db_name = \"itanong\"\n",
    "db = SQLDatabase.from_uri(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\")\n",
    "\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "  llm=llm,\n",
    "  toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n",
    "  verbose=True,\n",
    "  agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from operator import itemgetter\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mrm8488/t5-base-finetuned-wikiSQL\",\n",
    "    huggingfacehub_api_token=\"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\",\n",
    "    max_new_tokens=200  # Specify the parameter explicitly\n",
    ")\n",
    "\n",
    "# Database connection details\n",
    "db_user = \"username\"\n",
    "db_password = \"password\"\n",
    "db_host = \"localhost\"\n",
    "db_name = \"itanong\"\n",
    "\n",
    "# Initialize the SQL Database\n",
    "db = SQLDatabase.from_uri(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\")\n",
    "\n",
    "# Initialize the SQLDatabaseChain\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
    "\n",
    "# Initialize the toolkit\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "# Create the SQL Agent\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    ")\n",
    "\n",
    "# Define the query tool\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "\n",
    "# Create a prompt template for answering questions\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "# Define the answer chain\n",
    "answer = answer_prompt | llm | StrOutputParser()\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer\n",
    ")\n",
    "\n",
    "# Example query\n",
    "response = chain.invoke({\"question\": \"What category does apple fall under?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "chain = write_query | execute_query\n",
    "chain.invoke({\"question\": \"How many employees are there\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_db(query: str) -> str:\n",
    "    print(f\"Query: {query}\")\n",
    "    db_context = db_chain.invoke(query)\n",
    "    db_context = db_context['result'].strip()\n",
    "    print(f\"Result: {db_context}\")\n",
    "    return db_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(query: str) -> str:\n",
    "    db_context = retrieve_from_db(query)\n",
    "    \n",
    "    print(db_context)\n",
    "    \n",
    "    system_message = \"\"\"\n",
    "    You are an AI assistant specialized in providing accurate and up-to-date information on tariff rates for vegetables and fruits. Your goal is to assist users by answering their queries related to import and export tariffs, duties, and related regulations for various vegetables and fruits in the Philippines. You should provide clear and concise answers to the user's queries based on the information available in the database.\n",
    "\n",
    "    Example:\n",
    "    \n",
    "    Query: Under what category of goods do apples fall?\n",
    "\n",
    "    Context: \n",
    "    \n",
    "\n",
    "    Output:\n",
    "    The tariff rate for importing apples is 30%.\n",
    "    \"\"\"\n",
    "    \n",
    "    human_qry_template = HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"Query:\n",
    "        {human_input}\n",
    "        \n",
    "        Context:\n",
    "        {db_context}\n",
    "        \n",
    "        Output:\n",
    "        \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "      SystemMessage(content=system_message),\n",
    "      human_qry_template.format(human_input=query, db_context=db_context)\n",
    "    ]\n",
    "    response = llm(messages).content\n",
    "    print(response)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(\"what products are available?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "\n",
    "chain = create_sql_query_chain(llm, db)\n",
    "response = chain.invoke({\"question\": \"What category does apple fall under?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.run(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advisegpt_v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
